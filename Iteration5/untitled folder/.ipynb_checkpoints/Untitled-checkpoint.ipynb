{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2003 = pd.read_csv('Stormdata_2003.csv', na_values=['-'], delimiter=\",\", error_bad_lines=False, encoding = \"ISO-8859-1\")\n",
    "df_2004 = pd.read_csv('Stormdata_2004.csv', na_values=['-'], delimiter=\",\", error_bad_lines=False, encoding = \"ISO-8859-1\")\n",
    "df_2005 = pd.read_csv('Stormdata_2005.csv', na_values=['-'], delimiter=\",\", error_bad_lines=False, encoding = \"ISO-8859-1\")\n",
    "df_2006 = pd.read_csv('Stormdata_2006.csv', na_values=['-'], delimiter=\",\", error_bad_lines=False, encoding = \"ISO-8859-1\")\n",
    "df_2007 = pd.read_csv('Stormdata_2007.csv', na_values=['-'], delimiter=\",\", error_bad_lines=False, encoding = \"ISO-8859-1\")\n",
    "df_2008 = pd.read_csv('Stormdata_2008.csv', na_values=['-'], delimiter=\",\", error_bad_lines=False, encoding = \"ISO-8859-1\")\n",
    "df_2009 = pd.read_csv('Stormdata_2009.csv', na_values=['-'], delimiter=\",\", error_bad_lines=False, encoding = \"ISO-8859-1\")\n",
    "df_2010 = pd.read_csv('Stormdata_2010.csv', na_values=['-'], delimiter=\",\", error_bad_lines=False, encoding = \"ISO-8859-1\")\n",
    "df_2011 = pd.read_csv('Stormdata_2011.csv', na_values=['-'], delimiter=\",\", error_bad_lines=False, encoding = \"ISO-8859-1\")\n",
    "df_2012 = pd.read_csv('Stormdata_2012.csv', na_values=['-'], delimiter=\",\", error_bad_lines=False, encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>LAST_MOD_DATE</th>\n",
       "      <th>LAST_MOD_TIME</th>\n",
       "      <th>LAST_CERT_DATE</th>\n",
       "      <th>LAST_CERT_TIME</th>\n",
       "      <th>LAST_MOD</th>\n",
       "      <th>LAST_CERT</th>\n",
       "      <th>ADDCORR_FLG</th>\n",
       "      <th>ADDCORR_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [BEGIN_YEARMONTH, BEGIN_DAY, BEGIN_TIME, END_YEARMONTH, END_DAY, END_TIME, EPISODE_ID, EVENT_ID, STATE, STATE_FIPS, YEAR, MONTH_NAME, EVENT_TYPE, CZ_TYPE, CZ_FIPS, CZ_NAME, WFO, BEGIN_DATE_TIME, CZ_TIMEZONE, END_DATE_TIME, INJURIES_DIRECT, INJURIES_INDIRECT, DEATHS_DIRECT, DEATHS_INDIRECT, DAMAGE_PROPERTY, DAMAGE_CROPS, SOURCE, MAGNITUDE, MAGNITUDE_TYPE, FLOOD_CAUSE, CATEGORY, TOR_F_SCALE, TOR_LENGTH, TOR_WIDTH, TOR_OTHER_WFO, TOR_OTHER_CZ_STATE, TOR_OTHER_CZ_FIPS, TOR_OTHER_CZ_NAME, BEGIN_RANGE, BEGIN_AZIMUTH, BEGIN_LOCATION, END_RANGE, END_AZIMUTH, END_LOCATION, BEGIN_LAT, BEGIN_LON, END_LAT, END_LON, EPISODE_NARRATIVE, EVENT_NARRATIVE, LAST_MOD_DATE, LAST_MOD_TIME, LAST_CERT_DATE, LAST_CERT_TIME, LAST_MOD, LAST_CERT, ADDCORR_FLG, ADDCORR_DATE]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_cols = ['BEGIN_YEARMONTH', 'END_YEARMONTH']\n",
    "df_2004[df_2004['BEGIN_YEARMONTH'] != df_2004['END_YEARMONTH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_prediction_trial = pd.read_csv(\"prediction_trials.tsv\", na_values=['-'], delimiter=\"\\t\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_prediction_trial[\"start\"] = pd.to_datetime(df_prediction_trial[\"start\"])\n",
    "df_prediction_trial[\"end\"] = pd.to_datetime(df_prediction_trial[\"end\"])\n",
    "\n",
    "df_prediction_trial['month1'] = df_prediction_trial['start'].dt.month\n",
    "df_prediction_trial['month2'] = df_prediction_trial['end'].dt.month\n",
    "\n",
    "df_prediction_trial['year1'] = df_prediction_trial['start'].dt.year\n",
    "df_prediction_trial['year2'] = df_prediction_trial['end'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['BEGIN_YEARMONTH', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON', 'EVENT_TYPE', 'STATE']\n",
    "df_2003 = df_2003[cols]\n",
    "df_2004 = df_2004[cols]\n",
    "df_2005 = df_2005[cols]\n",
    "df_2006 = df_2006[cols]\n",
    "df_2007 = df_2007[cols]\n",
    "df_2008 = df_2008[cols]\n",
    "df_2009 = df_2009[cols]\n",
    "df_2010 = df_2010[cols]\n",
    "df_2011 = df_2011[cols]\n",
    "df_2012 = df_2012[cols]\n",
    "\n",
    "df_concat = pd.concat(\n",
    "[df_2003,\n",
    "df_2004,\n",
    "df_2005,\n",
    "df_2006,\n",
    "df_2007,\n",
    "df_2008,\n",
    "df_2009,\n",
    "df_2010,\n",
    "df_2011,\n",
    "df_2012]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14462, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat = df_concat[(df_concat[\"STATE\"] == \"DISTRICT OF COLUMBIA\")|(df_concat[\"STATE\"] == \"MARYLAND\")|(df_concat[\"STATE\"] == \"VIRGINIA\")]\n",
    "df_concat = df_concat[(pd.isnull(df_concat[\"BEGIN_LAT\"]) == False)]\n",
    "df_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>200302</td>\n",
       "      <td>36.72</td>\n",
       "      <td>-77.07</td>\n",
       "      <td>36.72</td>\n",
       "      <td>-77.07</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>2003</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>200302</td>\n",
       "      <td>36.72</td>\n",
       "      <td>-77.07</td>\n",
       "      <td>36.72</td>\n",
       "      <td>-77.07</td>\n",
       "      <td>Hail</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>2003</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>200302</td>\n",
       "      <td>36.67</td>\n",
       "      <td>-76.92</td>\n",
       "      <td>36.67</td>\n",
       "      <td>-76.92</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>2003</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6136</th>\n",
       "      <td>200302</td>\n",
       "      <td>36.78</td>\n",
       "      <td>-76.62</td>\n",
       "      <td>36.78</td>\n",
       "      <td>-76.62</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>2003</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6140</th>\n",
       "      <td>200302</td>\n",
       "      <td>37.02</td>\n",
       "      <td>-76.35</td>\n",
       "      <td>37.02</td>\n",
       "      <td>-76.35</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>2003</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>200302</td>\n",
       "      <td>36.87</td>\n",
       "      <td>-76.27</td>\n",
       "      <td>36.87</td>\n",
       "      <td>-76.27</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>2003</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>200302</td>\n",
       "      <td>36.82</td>\n",
       "      <td>-76.33</td>\n",
       "      <td>36.82</td>\n",
       "      <td>-76.33</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>2003</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>200302</td>\n",
       "      <td>36.82</td>\n",
       "      <td>-76.27</td>\n",
       "      <td>36.82</td>\n",
       "      <td>-76.27</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>2003</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177</th>\n",
       "      <td>200302</td>\n",
       "      <td>36.85</td>\n",
       "      <td>-75.98</td>\n",
       "      <td>36.85</td>\n",
       "      <td>-75.98</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>2003</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186</th>\n",
       "      <td>200302</td>\n",
       "      <td>36.85</td>\n",
       "      <td>-75.98</td>\n",
       "      <td>36.85</td>\n",
       "      <td>-75.98</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>2003</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BEGIN_YEARMONTH  BEGIN_LAT  BEGIN_LON  END_LAT  END_LON  \\\n",
       "6118           200302      36.72     -77.07    36.72   -77.07   \n",
       "6121           200302      36.72     -77.07    36.72   -77.07   \n",
       "6126           200302      36.67     -76.92    36.67   -76.92   \n",
       "6136           200302      36.78     -76.62    36.78   -76.62   \n",
       "6140           200302      37.02     -76.35    37.02   -76.35   \n",
       "6146           200302      36.87     -76.27    36.87   -76.27   \n",
       "6147           200302      36.82     -76.33    36.82   -76.33   \n",
       "6148           200302      36.82     -76.27    36.82   -76.27   \n",
       "6177           200302      36.85     -75.98    36.85   -75.98   \n",
       "6186           200302      36.85     -75.98    36.85   -75.98   \n",
       "\n",
       "             EVENT_TYPE     STATE  year month  \n",
       "6118  Thunderstorm Wind  VIRGINIA  2003    02  \n",
       "6121               Hail  VIRGINIA  2003    02  \n",
       "6126  Thunderstorm Wind  VIRGINIA  2003    02  \n",
       "6136            Tornado  VIRGINIA  2003    02  \n",
       "6140  Thunderstorm Wind  VIRGINIA  2003    02  \n",
       "6146  Thunderstorm Wind  VIRGINIA  2003    02  \n",
       "6147  Thunderstorm Wind  VIRGINIA  2003    02  \n",
       "6148  Thunderstorm Wind  VIRGINIA  2003    02  \n",
       "6177  Thunderstorm Wind  VIRGINIA  2003    02  \n",
       "6186  Thunderstorm Wind  VIRGINIA  2003    02  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findOverlappingRectangles(nw_lat1, nw_lat2, se_lat1, se_lat2, nw_long1, nw_long2, se_long1, se_long2):\n",
    "    if (float(nw_lat1) < float(se_lat2)) or (float(se_lat1) > float(nw_lat2)):\n",
    "        return False\n",
    "    if (float(nw_long1) > float(se_long2)) or (float(se_long1) < float(nw_long2)):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BEGIN_YEARMONTH', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
       "       'EVENT_TYPE', 'STATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_concat[\"year\"] = df_concat.apply(lambda row: int(str(row[\"BEGIN_YEARMONTH\"])[0:4]), axis =1)\n",
    "df_concat[\"month\"] = df_concat.apply(lambda row: int(str(row[\"BEGIN_YEARMONTH\"])[-2:]), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_prediction_trial[\"start\"] = pd.to_datetime(df_prediction_trial[\"start\"])\n",
    "df_prediction_trial[\"end\"] = pd.to_datetime(df_prediction_trial[\"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhisheknigam/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "from numpy import array\n",
    "\n",
    "lat_Long_Dict = {}\n",
    "start = time.time()\n",
    "index = 0\n",
    "def create_Lat_Long_Dict(row):\n",
    "    global index\n",
    "    all_overlap_boxes = []\n",
    "    for i in range(0,len(df_concat),1):\n",
    "        row1 = df_concat.iloc[i:i+1]\n",
    "        if findOverlappingRectangles(row1[\"BEGIN_LAT\"],row[\"nw_lat\"],row1[\"END_LAT\"],row[\"se_lat\"],row1[\"BEGIN_LON\"],row[\"nw_lon\"],row1[\"END_LON\"],row[\"se_lon\"]):\n",
    "            all_overlap_boxes.append(row1.values)\n",
    "    count = 0\n",
    "    true_positive = []\n",
    "    if(len(all_overlap_boxes) > 0):\n",
    "        for j in range(0,len(all_overlap_boxes),1):\n",
    "            data = all_overlap_boxes[j]\n",
    "            data = pd.DataFrame(data, columns = df_concat.columns)\n",
    "            if (int(data[\"month\"]) == int(row[\"start\"].month) or int(data[\"month\"]) == int(row[\"end\"].month)):\n",
    "                true_positive.extend(all_overlap_boxes[j])\n",
    "                count = count + 1\n",
    "    index = index + 1\n",
    "    test = pd.DataFrame(true_positive, columns = df_concat.columns)\n",
    "    test = test.sort_values([\"EVENT_TYPE\"])\n",
    "    test[\"EVENT_TYPE\"].to_csv(\"test\"+str(index)+\".tsv\",sep=\"\\t\", mode='w', index=False, header=None)\n",
    "    return count\n",
    "        \n",
    "trial_data = df_prediction_trial.head(100)\n",
    "trial_data[\"count_new\"] = trial_data.apply(lambda row:create_Lat_Long_Dict(row), axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      30\n",
       "1       0\n",
       "2     113\n",
       "3       6\n",
       "4      30\n",
       "5     182\n",
       "6      14\n",
       "7     187\n",
       "8      30\n",
       "9       8\n",
       "10      7\n",
       "11    209\n",
       "12     28\n",
       "13     30\n",
       "14     33\n",
       "15    129\n",
       "16     32\n",
       "17     26\n",
       "18      5\n",
       "19    331\n",
       "20    325\n",
       "21      4\n",
       "22    114\n",
       "23     37\n",
       "24    126\n",
       "25    199\n",
       "26    184\n",
       "27     51\n",
       "28      7\n",
       "29      7\n",
       "     ... \n",
       "70    124\n",
       "71    559\n",
       "72    124\n",
       "73     96\n",
       "74      8\n",
       "75    199\n",
       "76     30\n",
       "77      8\n",
       "78    153\n",
       "79      5\n",
       "80      7\n",
       "81      6\n",
       "82    141\n",
       "83     52\n",
       "84    178\n",
       "85     21\n",
       "86      0\n",
       "87    122\n",
       "88      8\n",
       "89      8\n",
       "90     90\n",
       "91     32\n",
       "92     47\n",
       "93    195\n",
       "94     24\n",
       "95    192\n",
       "96     35\n",
       "97    526\n",
       "98      7\n",
       "99     97\n",
       "Name: count_new, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_data[\"count_new\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_precipitation = pd.read_csv(\"856352.csv\", na_values=['-'], delimiter=\",\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_precipitation[\"DATE\"] = pd.to_datetime(df_precipitation[\"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_precipitation[\"year\"] = df_precipitation.apply(lambda row: int(row[\"DATE\"].year), axis =1)\n",
    "df_precipitation[\"month\"] = df_precipitation.apply(lambda row: int(row[\"DATE\"].month), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"count\"] = df[\"DATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "\n",
    "reg_iter = 1\n",
    "total_error_reg = []\n",
    "total_error_rbf = []\n",
    "total_error_poly = []\n",
    "total_error_svr = []\n",
    "\n",
    "def train_regression_model(x_train, y_train, x_test, y_test, x_predict):\n",
    "    if len(x_train) < 2 or len(x_test) == 0 or (len(x_train) != len(y_train)) or (len(x_test) != len(y_test)) :\n",
    "        return np.zeros(2)\n",
    "\n",
    "    global reg_iter\n",
    "    reg_iter = reg_iter + 1\n",
    "    \n",
    "    regression_model = LinearRegression()\n",
    "#      ridge_rbf = KernelRidge(alpha=2.0, kernel='rbf')\n",
    "#     ridge_poly = KernelRidge(alpha=2.0, kernel='sigmoid')\n",
    "#     svr_model = SVR(C=100.0, epsilon=0.2)\n",
    "    \n",
    "    regression_model.fit(x_train, y_train)\n",
    "#     ridge_rbf.fit(x_train, y_train)\n",
    "#     ridge_poly.fit(x_train, y_train)\n",
    "#     svr_model.fit(x_train, y_train)\n",
    "\n",
    "    predicted_regression = regression_model.predict(x_test)\n",
    "#     predicted_ridge_rbf = ridge_rbf.predict(x_test)\n",
    "#     predicted_ridge_poly = ridge_poly.predict(x_test)\n",
    "#     predicted_svr = svr_model.predict(x_test)\n",
    "\n",
    "    error_reg = np.mean((predicted_regression - y_test) ** 2)\n",
    "    total_error_reg.append(error_reg)\n",
    "    \n",
    "#     error_rbf = np.mean((predicted_ridge_rbf - y_test) ** 2)\n",
    "#     total_error_rbf.append(error_rbf)\n",
    "    \n",
    "#     error_poly = np.mean((predicted_ridge_poly - y_test) ** 2)\n",
    "#     total_error_poly.append(error_poly)\n",
    "    \n",
    "#     error_svr = np.mean((predicted_svr - y_test) ** 2)\n",
    "#     total_error_svr.append(error_svr)\n",
    "    \n",
    "    return regression_model.predict(x_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\t106.23861289024353\n",
      "20000\t124.51203799247742\n",
      "30000\t134.70792198181152\n",
      "40000\t133.75188088417053\n",
      "50000\t130.37349104881287\n",
      "60000\t162.66161394119263\n",
      "70000\t131.27982091903687\n",
      "80000\t139.84999108314514\n",
      "90000\t132.5072820186615\n",
      "100000\t166.53674387931824\n",
      "110000\t150.6023919582367\n",
      "120000\t122.56748700141907\n",
      "130000\t128.18423318862915\n",
      "140000\t120.0847659111023\n",
      "150000\t137.1595528125763\n",
      "160000\t136.2682499885559\n",
      "170000\t128.84276819229126\n",
      "180000\t125.54276013374329\n",
      "190000\t117.72907090187073\n",
      "200000\t119.78739213943481\n",
      "210000\t117.23363184928894\n",
      "220000\t115.7737250328064\n",
      "230000\t133.95081281661987\n",
      "240000\t129.0922291278839\n",
      "250000\t121.58417892456055\n",
      "260000\t152.38005113601685\n",
      "270000\t168.79933214187622\n",
      "280000\t137.59862303733826\n",
      "290000\t133.31682109832764\n",
      "300000\t127.89596915245056\n",
      "310000\t121.77971196174622\n",
      "320000\t143.96256494522095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhisheknigam/anaconda/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm reg mse : nan\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "from numpy import array\n",
    "\n",
    "total_error_reg = []\n",
    "total_error_rbf = []\n",
    "total_error_poly = []\n",
    "total_error_svr = []\n",
    "final_prec_result = []\n",
    "count = 0\n",
    "start = time.time()\n",
    "def create_precipitation_Dict(row):\n",
    "    columns1 = ['month1', 'year1']\n",
    "    columns2 = ['month2', 'year2']\n",
    "\n",
    "    df1 = pd.DataFrame(row[columns1])\n",
    "    df1 = df1.transpose()\n",
    "    df2 = pd.DataFrame(row[columns2])\n",
    "    df2 = df2.transpose()\n",
    "    df2.columns = columns1\n",
    "    x_predict = df1.append(df2)\n",
    "    \n",
    "    startMonth = int(row[\"start\"].month)\n",
    "    endMonth = int(row[\"end\"].month)\n",
    "    prec_data =  df_precipitation[((df_precipitation[\"month\"] == startMonth) | (df_precipitation[\"month\"] == endMonth))]\n",
    "    prec_data_group = prec_data.groupby([\"year\",\"month\"])[\"HPCP\"].sum().reset_index()\n",
    "    data_test = prec_data_group[prec_data_group['year'] == 2012]\n",
    "    data_train = prec_data_group[prec_data_group['year'] != 2012]\n",
    "    columns = ['month', 'year']\n",
    "    x_train, y_train, x_test, y_test = data_train[columns] ,data_train['HPCP'], data_test[columns], data_test['HPCP']\n",
    "    y_ = train_regression_model(x_train, y_train, x_test, y_test, x_predict)\n",
    "    final_prec_result.append(np.mean(y_,axis=0))\n",
    "    \n",
    "    global count\n",
    "    global start\n",
    "    count = count + 1\n",
    "    if count%10000 == 0:\n",
    "        end = time.time()\n",
    "        print (str(count) + '\\t' + str(end - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    return len(prec_data)\n",
    "        \n",
    "trial_data = df_prediction_trial\n",
    "trial_data[\"precipitation_count\"] = trial_data.apply(lambda row:create_precipitation_Dict(row), axis= 1)\n",
    "print('svm reg mse : ' + str(math.sqrt(np.mean(total_error_svr,axis=0))))\n",
    "\n",
    "df_final_output = pd.DataFrame(final_prec_result)\n",
    "df_final_output.to_csv(\"Linear_Regression_precipitation.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_precipitation = df_precipitation[~(df_precipitation[\"HPCP\"] == 999.99)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.58000000000004"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_precipitation[(df_precipitation[\"month\"] == 2) & (df_precipitation[\"year\"] == 2003)][\"HPCP\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new= df_precipitation.groupby([\"year\",\"month\"]).sum().reset_index()\n",
    "df_new.to_csv(\"individual_month_precipitation.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
